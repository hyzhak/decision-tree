{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "\n",
    "CART (Classification Trees), Breiman\n",
    "\n",
    "Binary tree, minimize error in each leaf\n",
    "\n",
    "## Lectures\n",
    "- https://www.youtube.com/watch?v=p17C9q2M00Q&list=PLD0F06AA0D2E8FFBA&index=7 (ML 2.1 - ML 2.8) mathematicalmonk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Growing a tree (\"Greedy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootsrap aggregation (Bagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on http://gabrielelanaro.github.io/blog/2016/03/03/decision-trees.html Implementing Decision Trees in Python. It is ID3/C4.5, isn't CART algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x_0 = 0': array([0]),\n",
      " 'x_0 = 1': array([0, 0]),\n",
      " 'x_0 = 2': {'x_1 = 0': array([0]), 'x_1 = 1': array([1, 1])}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "# x1 is weather type (0 = partly cloudy, 1 = cloudy, 2 = sunny)\n",
    "x1 = [0, 1, 1, 2, 2, 2]\n",
    "# x2 is atmospheric pressure (0 = low, 1 = high)\n",
    "x2 = [0, 0, 1, 1, 1, 0]\n",
    "# y is rain 1 or not rain 0\n",
    "y = np.array([0, 0, 0, 1, 1, 0])\n",
    "\n",
    "def partition(a):\n",
    "    return {c: (a==c).nonzero()[0] for c in np.unique(a)}\n",
    "\n",
    "def entropy(s):\n",
    "    res = 0\n",
    "    val, counts = np.unique(s, return_counts=True)\n",
    "    freqs = counts.astype('float') / len(s)\n",
    "    for p in freqs:\n",
    "        if p != 0.0:\n",
    "            res -= p * np.log2(p)\n",
    "    return res\n",
    "\n",
    "def mutual_information(y, x):\n",
    "\n",
    "    res = entropy(y)\n",
    "\n",
    "    # We partition x, according to attribute values x_i\n",
    "    val, counts = np.unique(x, return_counts=True)\n",
    "    freqs = counts.astype('float')/len(x)\n",
    "\n",
    "    # We calculate a weighted average of the entropy\n",
    "    for p, v in zip(freqs, val):\n",
    "        res -= p * entropy(y[x == v])\n",
    "\n",
    "    return res\n",
    "\n",
    "def is_pure(s):\n",
    "    return len(set(s)) == 1\n",
    "\n",
    "def recursive_split(x, y):\n",
    "    # If there could be no split, just return the original set\n",
    "    if is_pure(y) or len(y) == 0:\n",
    "        return y\n",
    "\n",
    "    # We get attribute that gives the highest mutual information\n",
    "    gain = np.array([mutual_information(y, x_attr) for x_attr in x.T])\n",
    "    selected_attr = np.argmax(gain)\n",
    "\n",
    "    # If there's no gain at all, nothing has to be done, just return the original set\n",
    "    if np.all(gain < 1e-6):\n",
    "        return y\n",
    "\n",
    "\n",
    "    # We split using the selected attribute\n",
    "    sets = partition(x[:, selected_attr])\n",
    "\n",
    "    res = {}\n",
    "    for k, v in sets.items():\n",
    "        y_subset = y.take(v, axis=0)\n",
    "        x_subset = x.take(v, axis=0)\n",
    "\n",
    "        res['x_%d = %d' % (selected_attr, k)] = recursive_split(x_subset, y_subset)\n",
    "\n",
    "    return res\n",
    "\n",
    "X = np.array([x1, x2]).T\n",
    "pprint(recursive_split(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base on http://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/ How To Implement The Decision Tree Algorithm From Scratch In Python (Classification and regression tree algorithm - CART).\n",
    "\n",
    "Used dataset from here http://archive.ics.uci.edu/ml/datasets/banknote+authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "    file = open(filename, 'rt')\n",
    "    lines = reader(file)\n",
    "    # convert str -> float\n",
    "    dataset = [list(map(float, row)) for row in lines]\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X1 < 6.642]\n",
      " [X1 < 2.771]\n",
      "  [0]\n",
      "  [X1 < 2.771]\n",
      "   [0]\n",
      "   [0]\n",
      " [X1 < 7.498]\n",
      "  [X1 < 7.445]\n",
      "   [1]\n",
      "   [1]\n",
      "  [X1 < 7.498]\n",
      "   [1]\n",
      "   [1]\n"
     ]
    }
   ],
   "source": [
    "# Split a dataset based on an attribute and an attribute value\n",
    "def test_split(index, value, dataset):\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right\n",
    "\n",
    "\n",
    "# Calculate the Gini index for a split dataset\n",
    "def gini_index(groups, class_values):\n",
    "    gini = 0.0\n",
    "    for class_value in class_values:\n",
    "        for group in groups:\n",
    "            size = len(group)\n",
    "            if size == 0:\n",
    "                continue\n",
    "            proportion = [row[-1] for row in group].count(class_value) / float(size)\n",
    "            gini += (proportion * (1.0 - proportion))\n",
    "    return gini\n",
    "\n",
    "\n",
    "# Select the best split point for a dataset\n",
    "def get_split(dataset):\n",
    "    class_values = list(set(row[-1] for row in dataset))\n",
    "    b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "    for index in range(len(dataset[0]) - 1):\n",
    "        for row in dataset:\n",
    "            groups = test_split(index, row[index], dataset)\n",
    "            gini = gini_index(groups, class_values)\n",
    "            if gini < b_score:\n",
    "                b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "    return {'index': b_index, 'value': b_value, 'groups': b_groups}\n",
    "\n",
    "\n",
    "# Create a terminal node value\n",
    "def to_terminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    return max(set(outcomes), key=outcomes.count)\n",
    "\n",
    "\n",
    "# Create child splits for a node or make terminal\n",
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['groups']\n",
    "    del (node['groups'])\n",
    "    # check for a no split\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    # check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    # process left child\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left)\n",
    "        split(node['left'], max_depth, min_size, depth + 1)\n",
    "    # process right child\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right)\n",
    "        split(node['right'], max_depth, min_size, depth + 1)\n",
    "\n",
    "\n",
    "# Build a decision tree\n",
    "def build_tree(train, max_depth, min_size):\n",
    "    root = get_split(train)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root\n",
    "\n",
    "\n",
    "# Print a decision tree\n",
    "def print_tree(node, depth=0):\n",
    "    if isinstance(node, dict):\n",
    "        print('%s[X%d < %.3f]' % ((depth * ' ', (node['index'] + 1), node['value'])))\n",
    "        print_tree(node['left'], depth + 1)\n",
    "        print_tree(node['right'], depth + 1)\n",
    "    else:\n",
    "        print('%s[%s]' % ((depth * ' ', node)))\n",
    "\n",
    "\n",
    "dataset = [[2.771244718, 1.784783929, 0],\n",
    "           [1.728571309, 1.169761413, 0],\n",
    "           [3.678319846, 2.81281357, 0],\n",
    "           [3.961043357, 2.61995032, 0],\n",
    "           [2.999208922, 2.209014212, 0],\n",
    "           [7.497545867, 3.162953546, 1],\n",
    "           [9.00220326, 3.339047188, 1],\n",
    "           [7.444542326, 0.476683375, 1],\n",
    "           [10.12493903, 3.234550982, 1],\n",
    "           [6.642287351, 3.319983761, 1]]\n",
    "tree = build_tree(dataset, 5, 1)\n",
    "print_tree(tree)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model on banknote auth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load and prepare data\n",
    "filename = './dataset/data_banknote_authentication.csv'\n",
    "dataset = load_csv(filename)\n",
    "dataset_array = np.array(dataset)\n",
    "dataset_train, dataset_test = train_test_split(dataset_array, test_size=0.33, random_state=42)\n",
    "\n",
    "# train model\n",
    "tree = build_tree(dataset_train, 5, 1)\n",
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make prediction and estimate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a prediction with a decision tree\n",
    "def predict(node, row):\n",
    "    if row[node['index']] < node['value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']\n",
    "        \n",
    "error = 0\n",
    "for row in dataset_test:\n",
    "    prediction = predict(tree, row)\n",
    "    error += abs(row[-1] - prediction)\n",
    "    \n",
    "error = 1 - error/len(dataset_test)\n",
    "    \n",
    "print('Accuracy: {}'.format(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib\n",
    "# use color map, otherwise it will be grayscale\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "# can choose different styles\n",
    "# print(plt.style.available)\n",
    "plt.style.use('fivethirtyeight')\n",
    "# list available fonts: [f.name for f in matplotlib.font_manager.fontManager.ttflist]\n",
    "matplotlib.rc('font', family='DejaVu Sans') \n",
    "\n",
    "\n",
    "# draw dataset\n",
    "\n",
    "np_dataset = np.array(dataset)\n",
    "y = np_dataset[:, -1]\n",
    "# actually we could use label_to_idx=y, because we have label as number here \n",
    "label_to_idx = [list(set(y)).index(y_value) for y_value in y]\n",
    "plt.scatter(x=np_dataset[:, 0], y=np_dataset[:,1], c=label_to_idx, cmap=cm.jet)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
